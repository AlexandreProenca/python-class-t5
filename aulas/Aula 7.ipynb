{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiros passos com testes\n",
    "-------\n",
    "\n",
    "### O Básico\n",
    "\n",
    "Em Python, quando queremos escrever testes unitários podemos lançar mãos desde um simples **assert**, passando por funções auxiliares até um framework de testes unitários completo. Nesta aula vou mostrar rapidamente como funciona o statement **assert** e mostrar também algumas funções que também podem ser úteis.\n",
    "\n",
    "O statement aceita como segundo parâmetro uma string que pode ser um mensagem explicativa e é exibida quando a asserção falha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-a871fdc9ebee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "mensagem explicativa",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-340917a136f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"mensagem explicativa\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: mensagem explicativa"
     ]
    }
   ],
   "source": [
    "assert False, \"mensagem explicativa\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exemplificar o funcionamento do statement, veja o trecho de código abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "100 deve ser maior que 'b'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-54e7c10cbc54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mmensagem\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m\"100\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mexpressao\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmensagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: 100 deve ser maior que 'b'"
     ]
    }
   ],
   "source": [
    "b = 150\n",
    "expressao = 100 > b\n",
    "\n",
    "if expressao == False:\n",
    "    mensagem  = \"100 deve ser maior que 'b'\"\n",
    "else:\n",
    "    mensagem  = \"100\"\n",
    "\n",
    "assert 3 > 4, 'nao é maior'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O que vem depois ?\n",
    "Se ao invés do \"assert\", você quisesse utilizar uma função, por exemplo, test() para realizar pequenos testes, como seria a implementação dessa função?\n",
    "\n",
    "Que tal o exemplo abaixo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(expression1, expression2):\n",
    "    if expression1 == expression2:\n",
    "        return 'Pass'\n",
    "    else:\n",
    "        return 'Fail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unit Testing Framework\n",
    "\n",
    "O Unit Testing Framework pode ser o que você esteja procurando.\n",
    "\n",
    "Longe de querer se aprofundar no framework (leia a documentação), vou apenas mostrar dois exemplos do tipo \"Hello world\".\n",
    "\n",
    "Abaixo um exemplo demonstrando como testar uma simples função."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "def fun(x):\n",
    "    return x + 1\n",
    "\n",
    "class MyTest(unittest.TestCase):\n",
    "    def test(self):\n",
    "        self.assertEqual(fun(3), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doctest\n",
    "------\n",
    "O módulo doctest pesquisa por partes do texto que se parecem com sessões interativas do Python em docstrings e, em seguida, executa essas sessões para verificar se elas funcionam exatamente como mostrado.\n",
    "\n",
    "Os testes de documentos têm um caso de uso diferente dos testes de unidade adequados: geralmente são menos detalhados e não capturam casos especiais ou erros de regressão obscuros. Eles são úteis como uma documentação expressiva dos principais casos de uso de um módulo e seus componentes. No entanto, os testes de documentos devem ser executados automaticamente sempre que o conjunto de testes completo for executado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(x):\n",
    "    \"\"\"Return the square of x.\n",
    "\n",
    "    >>> square(2)\n",
    "    4\n",
    "    >>> square(-2)\n",
    "    4\n",
    "    \"\"\"\n",
    "\n",
    "    return x * x\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import doctest\n",
    "    doctest.testmod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramentas\n",
    "-----\n",
    "Pytest\n",
    "\n",
    "A estrutura pytest facilita a criação de pequenos testes, mas é dimensionada para oferecer suporte a testes funcionais complexos para aplicativos e bibliotecas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytest in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (5.2.2)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (0.23)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (19.1.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (7.2.0)\n",
      "Requirement already satisfied: packaging in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (19.2)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (1.3.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (1.8.0)\n",
      "Requirement already satisfied: wcwidth in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (0.1.7)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from pytest) (0.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest) (0.6.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from packaging->pytest) (2.4.2)\n",
      "Requirement already satisfied: six in /Users/alexandre/Projects/py3-env/lib/python3.7/site-packages (from packaging->pytest) (1.12.0)\n",
      "\u001b[33mWARNING: You are using pip version 19.2.2, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install pytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# content of test_sample.py\n",
    "def inc(x):\n",
    "    return x + 1\n",
    "\n",
    "\n",
    "def test_answer():\n",
    "    assert inc(3) == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request\n",
    "\n",
    "def speak():\n",
    "    with urllib.request.urlopen('http://www.casadobruxo.com.br/textos/reflex.htm') as raw_content:\n",
    "        html_content = raw_content.read()\n",
    "\n",
    "    s = BeautifulSoup(html_content)\n",
    "    frases = s.find_all(\"p\", attrs={\"align\": \"justify\"})\n",
    "    r = [item.text for item in frases]\n",
    "    frase = r[0].split('\\n\\n')\n",
    "    arr = []\n",
    "    for i in range(4,111):\n",
    "        arr.append(frase[i].split('\"')[1])\n",
    "\n",
    "    return random.choice(arr)\n",
    "\n",
    "def test_speak_kind():\n",
    "    assert isinstance(str, speak())\n",
    "\n",
    "def test_speak_length():\n",
    "    assert len(speak()) > 20\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
